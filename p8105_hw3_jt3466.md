p8105_hw3_jt3466
================
Johnstone Tcheou
2024-10-10

# Homework 3

The `tidyverse`, `p8105.datasets`, `patchwork`, and `ggridges` packages
have been loaded.

## Problem 1

``` r
data("ny_noaa")

ny_noaa |> 
  summary()
```

    ##       id                 date                 prcp               snow       
    ##  Length:2595176     Min.   :1981-01-01   Min.   :    0.00   Min.   :  -13   
    ##  Class :character   1st Qu.:1988-11-29   1st Qu.:    0.00   1st Qu.:    0   
    ##  Mode  :character   Median :1997-01-21   Median :    0.00   Median :    0   
    ##                     Mean   :1997-01-01   Mean   :   29.82   Mean   :    5   
    ##                     3rd Qu.:2005-09-01   3rd Qu.:   23.00   3rd Qu.:    0   
    ##                     Max.   :2010-12-31   Max.   :22860.00   Max.   :10160   
    ##                                          NA's   :145838     NA's   :381221  
    ##       snwd            tmax               tmin          
    ##  Min.   :   0.0   Length:2595176     Length:2595176    
    ##  1st Qu.:   0.0   Class :character   Class :character  
    ##  Median :   0.0   Mode  :character   Mode  :character  
    ##  Mean   :  37.3                                        
    ##  3rd Qu.:   0.0                                        
    ##  Max.   :9195.0                                        
    ##  NA's   :591786

``` r
ny_noaa |> 
  head()
```

    ## # A tibble: 6 × 7
    ##   id          date        prcp  snow  snwd tmax  tmin 
    ##   <chr>       <date>     <int> <int> <int> <chr> <chr>
    ## 1 US1NYAB0001 2007-11-01    NA    NA    NA <NA>  <NA> 
    ## 2 US1NYAB0001 2007-11-02    NA    NA    NA <NA>  <NA> 
    ## 3 US1NYAB0001 2007-11-03    NA    NA    NA <NA>  <NA> 
    ## 4 US1NYAB0001 2007-11-04    NA    NA    NA <NA>  <NA> 
    ## 5 US1NYAB0001 2007-11-05    NA    NA    NA <NA>  <NA> 
    ## 6 US1NYAB0001 2007-11-06    NA    NA    NA <NA>  <NA>

This dataset has 2595176 observations and 7 7 variables. The dataset
consists of daily weather data from 1981-01-01 to 2010-12-31 for 747
different weather stations around NYC. The data is grouped by station,
identified by weather station ID (`id`) in ascending date order, with
observations for precipitation in 10ths of a mm (`prcp`), snowfall in mm
(`snow`), snow depth in mm (`snwd`), max temperature in degrees C
(`tmax`), and minimum temperature in degrees C (`tmin`).

The max temperature and minimum temperature variables are set to be
character variables, so they should be changed to a numeric type instead
like float to retain the 10ths of an mm precision.

``` r
ny_noaa <- ny_noaa |> 
  mutate(
    tmax = as.double(tmax, digits = 2),
    tmin = as.double(tmin, digits = 2),
    month = month(date),
    year = year(date)
  ) 

ny_noaa |> 
  summary()
```

    ##       id                 date                 prcp               snow       
    ##  Length:2595176     Min.   :1981-01-01   Min.   :    0.00   Min.   :  -13   
    ##  Class :character   1st Qu.:1988-11-29   1st Qu.:    0.00   1st Qu.:    0   
    ##  Mode  :character   Median :1997-01-21   Median :    0.00   Median :    0   
    ##                     Mean   :1997-01-01   Mean   :   29.82   Mean   :    5   
    ##                     3rd Qu.:2005-09-01   3rd Qu.:   23.00   3rd Qu.:    0   
    ##                     Max.   :2010-12-31   Max.   :22860.00   Max.   :10160   
    ##                                          NA's   :145838     NA's   :381221  
    ##       snwd             tmax              tmin             month       
    ##  Min.   :   0.0   Min.   :-389.0    Min.   :-594.0    Min.   : 1.000  
    ##  1st Qu.:   0.0   1st Qu.:  50.0    1st Qu.: -39.0    1st Qu.: 4.000  
    ##  Median :   0.0   Median : 150.0    Median :  33.0    Median : 7.000  
    ##  Mean   :  37.3   Mean   : 139.8    Mean   :  30.3    Mean   : 6.565  
    ##  3rd Qu.:   0.0   3rd Qu.: 233.0    3rd Qu.: 111.0    3rd Qu.:10.000  
    ##  Max.   :9195.0   Max.   : 600.0    Max.   : 600.0    Max.   :12.000  
    ##  NA's   :591786   NA's   :1134358   NA's   :1134420                   
    ##       year     
    ##  Min.   :1981  
    ##  1st Qu.:1988  
    ##  Median :1997  
    ##  Mean   :1996  
    ##  3rd Qu.:2005  
    ##  Max.   :2010  
    ## 

After changing the temperature variables to be a more sensible data
type, there are a variety of missing values and less reasonable
observations, like a minimum snow fall of -13 mm, a minimum maximum
temperature of -389 degrees C, a minimum minimum temperature of -594
degrees C, and a 25th percentile of minimum temperature of -39. These
are likely data entry errors, as some of these temperatures are just
impossible to survive in.

For missing values, there are 145838 missing values for precipitation,
381221 missing values for snowfall, 145838 missing values for snowdepth.

### What are the most commonly observed values for snowfall? Why?

``` r
ny_noaa |> 
  group_by(snow) |> 
  summarize(count = n()) |> 
  arrange(desc(count))
```

    ## # A tibble: 282 × 2
    ##     snow   count
    ##    <int>   <int>
    ##  1     0 2008508
    ##  2    NA  381221
    ##  3    25   31022
    ##  4    13   23095
    ##  5    51   18274
    ##  6    76   10173
    ##  7     8    9962
    ##  8     5    9748
    ##  9    38    9197
    ## 10     3    8790
    ## # ℹ 272 more rows

The most commonly observed snowfall value is 0 mm with 2008508
observations. This makes since given snow is only for a few months in a
year. The next most observed value, besides `NA`, is 25, 13, and 51 mm.

``` r
ny_noaa |> 
  drop_na() |> 
  filter(month == 1 | month == 7) |> 
  group_by(month, year, id) |> 
  summarize(avg_tmax = mean(tmax, na.rm = TRUE)) |> 
  ggplot(aes(x = year, y = avg_tmax,  fill = month)) +
  geom_bar(stat = "identity") +
  facet_grid(. ~ month)
```

    ## `summarise()` has grouped output by 'month', 'year'. You can override using the
    ## `.groups` argument.

![](p8105_hw3_jt3466_files/figure-gfm/avg%20max%20January%20temp%20vs%20years-1.png)<!-- --> -
There do not really seem to be any outliers. - Lots of variation around
0 degrees for January average max temperatures. - Average max
temperatures in July actually seem to be decreasing over the years,
interestingly enough.

``` r
tmax_tmin <- ny_noaa |> 
  drop_na() |> 
  ggplot(aes(x = tmin, y = tmax)) + 
    geom_hex()

snowfall_dist <- ny_noaa |> 
  drop_na() |> 
  filter((snow > 0 & snow < 100)) |> 
  group_by(year) |> 
  ggplot(aes(x = snow, y = as.factor(year))) +
  geom_density_ridges()

tmax_tmin + snowfall_dist
```

    ## Picking joint bandwidth of 4.24

![](p8105_hw3_jt3466_files/figure-gfm/two%20panel%20plot-1.png)<!-- -->

## Problem 2

### Import and tidy data

The demographic data is more or less in long format, but the
accelerometer data is in wide format, with a variable for each reading
of the 1440 minutes of the 24 hour day.

This accelerometer data will need to be pivoted longer prior to joining.
The left join is done on the accelerometer data, as if there are
participants with no accelerometer data, it does not make much sense to
include them. This way, only participants with accelerometer are
retained. The demographic variables are moved to be first after `SEQN`,
followed by the reading for that given minute.

``` r
demog_df <- read_csv("data/nhanes_covar.csv", skip = 4, na = c("NA", "", "."))
```

    ## Rows: 250 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (5): SEQN, sex, age, BMI, education
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(demog_df)
```

    ## # A tibble: 6 × 5
    ##    SEQN   sex   age   BMI education
    ##   <dbl> <dbl> <dbl> <dbl>     <dbl>
    ## 1 62161     1    22  23.3         2
    ## 2 62164     2    44  23.2         3
    ## 3 62169     1    21  20.1         2
    ## 4 62174     1    80  33.9         3
    ## 5 62177     1    51  20.1         2
    ## 6 62178     1    80  28.5         2

``` r
accel_df <- read_csv("data/nhanes_accel.csv", na = c("NA", "", "."))
```

    ## Rows: 250 Columns: 1441
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (1441): SEQN, min1, min2, min3, min4, min5, min6, min7, min8, min9, min1...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(accel_df)
```

    ## # A tibble: 6 × 1,441
    ##    SEQN  min1  min2  min3  min4   min5   min6  min7   min8    min9  min10  min11
    ##   <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>  <dbl>   <dbl>  <dbl>  <dbl>
    ## 1 62161 1.11  3.12  1.47  0.938 1.60   0.145  2.10  0.509   1.63   1.20   0.947 
    ## 2 62164 1.92  1.67  2.38  0.935 2.59   5.22   2.39  4.90    1.97   3.13   2.77  
    ## 3 62169 5.85  5.18  4.76  6.48  6.85   7.24   6.12  7.48    5.47   6.49   5.14  
    ## 4 62174 5.42  3.48  3.72  3.81  6.85   4.45   0.561 1.61    0.698  2.72   4.85  
    ## 5 62177 6.14  8.06  9.99  6.60  4.57   2.78   7.10  7.25   10.1    7.49   2.72  
    ## 6 62178 0.167 0.429 0.131 1.20  0.0796 0.0487 0.106 0.0653  0.0564 0.0639 0.0909
    ## # ℹ 1,429 more variables: min12 <dbl>, min13 <dbl>, min14 <dbl>, min15 <dbl>,
    ## #   min16 <dbl>, min17 <dbl>, min18 <dbl>, min19 <dbl>, min20 <dbl>,
    ## #   min21 <dbl>, min22 <dbl>, min23 <dbl>, min24 <dbl>, min25 <dbl>,
    ## #   min26 <dbl>, min27 <dbl>, min28 <dbl>, min29 <dbl>, min30 <dbl>,
    ## #   min31 <dbl>, min32 <dbl>, min33 <dbl>, min34 <dbl>, min35 <dbl>,
    ## #   min36 <dbl>, min37 <dbl>, min38 <dbl>, min39 <dbl>, min40 <dbl>,
    ## #   min41 <dbl>, min42 <dbl>, min43 <dbl>, min44 <dbl>, min45 <dbl>, …

``` r
accel_df <- accel_df |> 
  pivot_longer(
    cols = min1:min1440,
    values_to = "reading",
    names_to = "min",
    names_prefix = "min"
  )

mims_df <- accel_df |> 
  left_join(
    demog_df,
    by = join_by(SEQN)
  ) |> 
  select(SEQN, sex, age, BMI, education, everything())

head(mims_df)
```

    ## # A tibble: 6 × 7
    ##    SEQN   sex   age   BMI education min   reading
    ##   <dbl> <dbl> <dbl> <dbl>     <dbl> <chr>   <dbl>
    ## 1 62161     1    22  23.3         2 1       1.11 
    ## 2 62161     1    22  23.3         2 2       3.12 
    ## 3 62161     1    22  23.3         2 3       1.47 
    ## 4 62161     1    22  23.3         2 4       0.938
    ## 5 62161     1    22  23.3         2 5       1.60 
    ## 6 62161     1    22  23.3         2 6       0.145

After the data is merged, we need to exclude participants below 21 years
old, remove participants without demographic data, and change variables
to sensible variable classes, i.e. `min` should be a double instead and
factors should be introduced to `education` and `sex` to introduce
levels. This gives us a final dataset size of 360000 observations and 7
variables.

``` r
mims_df <- mims_df |> 
  filter(age > 21) |> 
  drop_na(sex, age, BMI, education) |> 
  mutate(
    min = as.double(min),
    sex = 
      case_match(
        sex,
        1 ~ "Male",
        2 ~ "Female"
      ),
    sex = factor(sex),
    education =
      case_match(
        education,
        1 ~ "Less than high school",
        2 ~ "High school equivalent",
        3 ~ "More than high school"
      ),
    education = factor(education, levels = c("Less than high school", "High school equivalent", "More than high school"))
  )    
```

### Table and graphs by gender and education level

Once the data is cleaned further to keep only the observations we want
to analyze, we can put them into a table and visualize the age
distributions by gender and education.

First, group the dataframe by `education` and `sex`, then get the total
number of participants per education and sex combination using
`summarize` and `n()`. Pivot the data wider for the table to get the
counts per sex each in their own column, with education status by rows.
Pipe this output into `kable` for a nice looking table.

Out of the 225 participants, 28 are females with less than high school
education, 27 are males with less than high school education, 23 are
females with high school equivalent education, 34 are males with high
school equivalent education, 59 females have more than high school
education, and 54 males have more than high school education.

For the graphs, there are separate violin graphs by education level,
with female participants in red and male participants in red. Age is on
the y axis and sex is on the x axis.

``` r
mims_df |> 
  group_by(education, sex) |> 
  summarize(count = n_distinct(SEQN)) |> 
  pivot_wider(
    names_from = sex,
    values_from = count
  ) |> 
  knitr::kable(
    col.names = c("Education", "Female", "Male")
  )
```

    ## `summarise()` has grouped output by 'education'. You can override using the
    ## `.groups` argument.

| Education              | Female | Male |
|:-----------------------|-------:|-----:|
| Less than high school  |     28 |   27 |
| High school equivalent |     23 |   34 |
| More than high school  |     59 |   54 |

``` r
mims_df |> 
  group_by(education, sex, age) |> 
  summarize(count = n()) |> 
  ggplot(aes(x = sex, y = age, fill = sex)) +
  geom_violin(alpha = 0.5) +
  stat_summary(fun = "median") + 
  labs(
    title = "Age distributions of participants",
    subtitle = "Stratified by sex and education",
    y = "Age (years)", 
    x = "Sex", 
    fill = "Sex") +
  facet_grid(. ~ education) 
```

    ## `summarise()` has grouped output by 'education', 'sex'. You can override using
    ## the `.groups` argument.

    ## Warning: Removed 2 rows containing missing values or values outside the scale range
    ## (`geom_segment()`).
    ## Removed 2 rows containing missing values or values outside the scale range
    ## (`geom_segment()`).
    ## Removed 2 rows containing missing values or values outside the scale range
    ## (`geom_segment()`).

![](p8105_hw3_jt3466_files/figure-gfm/p2%20table%20and%20distributions-1.png)<!-- -->

In the less than high school group, the women tend to be older, with the
lowest female age around 27 and the lowest male age around 23. The males
are somewhat bimodal, with a pronounced hump around 45 and a smaller
hump towards 75. In contrast, the females are more or less smooth from
45 up to 70.

Among the high school equivalent group, the age distribution for women
is an inverted pyramid, where there are fewer younger women, while the
age distribution for men is more of a typical pyramid with fewer older
men and a slight peak just under 60 years old. For the less than high
school

Lastly, within the more than high school group, both distributions are
skewed towards younger ages. There is a hump among females around 35 and
among males around 45.

### Total activity by age, sex, and education level

In order to get the total activity for an individual, we need to group
by an individual’s identifier, `SEQN`, along with their demographic
variables i.e. `sex`, `age`, and `education` for later visualization,
and then `summarize` using `sum` to sum the readings over the 24-hour
period, naming it as a variable `total_activity`.

As above, the scatterplots are separated by education level, with female
participants in red and male participants in red. Total activity over
the 24 hour period is on the Y axis and age is on the x axis. A smooth
loess curve is overlaid on top of the scatter points.

``` r
mims_df |> 
  group_by(SEQN, sex, age, BMI, education) |> 
  summarize(total_activity = sum(reading)) |> 
  ggplot(aes(x = age, y = total_activity, color = sex)) + 
  geom_point(alpha = 0.5) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Total physical activity registered by accelerometer over 24 hours",
    subtitle = "Stratified by sex and education",
    y = "Total activity", 
    x = "Age (years)", 
    color = "Sex"
    ) +
  facet_grid(. ~ education) 
```

    ## `summarise()` has grouped output by 'SEQN', 'sex', 'age', 'BMI'. You can
    ## override using the `.groups` argument.
    ## `geom_smooth()` using method = 'loess' and formula = 'y ~ x'

![](p8105_hw3_jt3466_files/figure-gfm/total%20activity-1.png)<!-- -->
Some observations from the above graphs:

- Among the less than high school group,
  - The points show a somewhat negative linear relationship, with
    activity decreasing as age increases.
  - The trendline somewhat has two modes, with humps around the 25 and
    60 year ranges in both sexes.
  - There is a sharp decline in activity in both sexes after the 60 year
    hump.
  - Females have more total physical activity until around 37 years old
    where males start to overtake the females.
  - The highest total activity among the less than high school group is
    higher than the highest total activity in the high school equivalent
    group.
- Among the high school equivalent group,
  - The points also show a slight negative linear relationship, but with
    greater scatter and variance than the less than high school group.
  - There is also a stronger bimodal trend with the loess curves,
    suggesting against a linear relationship between age and total
    activity.
  - The largest peak is around 40 years old with a smaller peak around
    70 years old.
  - Females have more total activity than males for most of this group.
- Among the more than high school group,
  - There appear to be much many more participants with more than high
    school education than the other education levels.
  - The linear relationship is less clear in this group, with more
    points scattered around and greater variance at the younger ages
    than in the older ages.
  - There is a notable outlier with activity near 0 (301 specifically,
    with `SEQN` 6.2357^{4}), which may warrant revisiting to see if
    anything happened during data entry for this individual.

### Activity over the day by sex

``` r
mims_df |>  
  ggplot(aes(x = min, y = reading, color = sex, fill = sex)) + 
  geom_point(alpha = 0.052) +  
  geom_smooth(aes(color = sex), se = FALSE) +
  labs(
    title = "24-hour physical activity registered by accelerometer",
    subtitle = "Stratified by sex and education",
    y = "Total activity", 
    x = "Time (mins)", 
    color = "Sex", 
    fill = "Sex"
    ) +
  facet_grid(. ~ education) 
```

    ## `geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = "cs")'

![](p8105_hw3_jt3466_files/figure-gfm/activity%20by%20sex%20by%20education-1.png)<!-- -->
Based on the graph, most people are active by 8:30 AM. Males with higher
than high school education are more active than other combinations of
sex and education status, particularly between the 7 AM to 9 PM range.
Females appear to be slightly more active than males throughout the day
for high school equivalent education and more than high school
education, though the gap between sexes is closer in the less than high
school group.

## Problem 3

### Import and tidy data

First step is to import the data for of each of the timepoints using
`read_csv`, catching potential `NA` values like `""`. `"."`, or `"NA"`.

Afterwards, the data is already in long format, with tidied variable
names (no spaces, all lowercase). In anticipation of combining the
datasets, create a variable for the year called `year` and month called
`month` to identify which dataset each observation came from. Combine
the 4 datasets using `bind_rows` and pipe it into `drop_na()` to get rid
of `NA` observations. Save this tidied dataset as `citi_df`.

``` r
jan_20_citi <- read_csv("data/Jan 2020 Citi.csv", na = c("", ".", "NA")) |>
  mutate(
    month = "January",
    year = "2020"
  )
```

    ## Rows: 12420 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (6): ride_id, rideable_type, weekdays, start_station_name, end_station_n...
    ## dbl (1): duration
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
jul_20_citi <- read_csv("data/July 2020 Citi.csv", na = c("", ".", "NA")) |> 
  mutate(
    month = "July",
    year = "2020"
  )
```

    ## Rows: 21048 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (6): ride_id, rideable_type, weekdays, start_station_name, end_station_n...
    ## dbl (1): duration
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
jan_24_citi <- read_csv("data/Jan 2024 Citi.csv", na = c("", ".", "NA")) |> 
  mutate(
    month = "January",
    year = "2024"
  )
```

    ## Rows: 18861 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (6): ride_id, rideable_type, weekdays, start_station_name, end_station_n...
    ## dbl (1): duration
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
jul_24_citi <- read_csv("data/July 2024 Citi.csv", na = c("", ".", "NA")) |> 
  mutate(
    month = "July",
    year = "2024"
  )
```

    ## Rows: 47156 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (6): ride_id, rideable_type, weekdays, start_station_name, end_station_n...
    ## dbl (1): duration
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
citi_df <- bind_rows(jan_20_citi, jul_20_citi, jan_24_citi, jul_24_citi) |> 
  drop_na()
```

### Rides by month and membership status

Once `citi_df` is created, group it by `year`, `month`, and
`member_casual` to separate casual riders and CitiBike members.
Calculate the total number of rides per combination of membership
status, month, and year using `summarize` and `n()`. Pivot this
summarized output wider for enhanced readability, creating a separate
column for total rides by casual users and total rides by members for
that given month. Pipe the pivoted output into `kable()` to make for a
readable table.

``` r
citi_df |> 
  group_by(year, month, member_casual) |> 
  summarize(total_rides = n()) |> 
  pivot_wider(
    names_from = c(member_casual),
    names_prefix = "total_rides_",
    values_from = total_rides
  ) |> 
  knitr::kable(col.names = c("Year", "Month", "Number of rides from casual users", "Number of rides from members")) 
```

    ## `summarise()` has grouped output by 'year', 'month'. You can override using the
    ## `.groups` argument.

| Year | Month   | Number of rides from casual users | Number of rides from members |
|:-----|:--------|----------------------------------:|-----------------------------:|
| 2020 | January |                               980 |                        11418 |
| 2020 | July    |                              5625 |                        15388 |
| 2024 | January |                              2094 |                        16705 |
| 2024 | July    |                             10843 |                        36200 |

Understandably, there are the least rides taken early on in January
2020, likely due to social distancing. However, there was a not much a
decline in rides by members in that timeframe, while most of the decline
happened in casual members. By July, casual rides increased, as did
member rides, but on a smaller scale relative to the January 2020 rides.
Interestingly, in January 2024, there was a decrease in the casual rides
while member rides increased slightly. July 2024 was the apex of rides,
with more than double the member rides and almost 5 times the casual
rides.

### 5 most popular stations in July 2024

First, we need to filter for only observations in July 2024, using
`filter` and the conditions of `year == 2024` and `month = 7`. Then, we
can group by `start_station_name` and then `summarize` with `n()` to get
the total rides originating from these starting stations. We can then
`arrange` by `total_rides_from` in descending order to get the most
popular stations at the top, and use `head()` to get the first 5
observations, i.e. the 5 most popular stations only. There is no
pivoting wider needed, so we can just pipe it into `kable()` and use the
`col.names` argument to label columns more explicitly.

``` r
citi_df |> 
  filter(year == "2024" & month == "July") |> 
  group_by(start_station_name) |> 
  summarize(total_rides_from = n()) |> 
  arrange(desc(total_rides_from)) |> 
  head(n = 5) |> 
  knitr::kable(
    col.names = c("5 most popular stations", "Total rides from these stations")
  )
```

| 5 most popular stations  | Total rides from these stations |
|:-------------------------|--------------------------------:|
| Pier 61 at Chelsea Piers |                             163 |
| University Pl & E 14 St  |                             155 |
| W 21 St & 6 Ave          |                             152 |
| West St & Chambers St    |                             150 |
| W 31 St & 7 Ave          |                             145 |

### Plot of time against median ride duration

We need to create separate boxplots for `weekdays` against ride
duration, `month` against ride duration, and `year` against ride
duration. For `weekdays`, we have the additional step of using
`fct_relevel` to reorder the factor levels so that the corresponding
boxplots are in corresponding order of the days of the week, rather than
alphabetical. The graphs are then combined in one figure using the
`patchwork` package, with a title and subtitle overlaid the grouped
boxplots.

``` r
# citi_df |> 
#   ggplot(aes(x = year, y = duration, color = year)) +
#   geom_boxplot() + 
#   geom_boxplot(aes(x = weekdays, y = duration, color = weekdays)) +
#   geom_boxplot(aes(x = month, y = duration, color = month))


days_plot <- citi_df |> 
  mutate(
    weekdays = forcats::fct_relevel(weekdays, c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
  ) |> 
  ggplot(aes(x = weekdays, y = duration, color = weekdays)) +
  geom_boxplot(show.legend = FALSE) +
  labs(
    x = "Days of the week",
    y = "Ride duration"
  ) +
  viridis::scale_color_viridis(discrete = TRUE, option = "turbo") +
  theme(legend.position = "none")

months_plot <- citi_df |> 
  ggplot(aes(x = month, y = duration, color = month)) +
  geom_boxplot(show.legend = FALSE) +
  labs(
    x = "Month",
    y = "Ride duration"
  ) +
  viridis::scale_color_viridis(discrete = TRUE, option = "viridis") +
  theme(legend.position = "none")

years_plot <- citi_df |> 
  ggplot(aes(x = year, y = duration, color = year)) +
  geom_boxplot() + 
  labs(
    x = "Year",
    y = ""
  ) + 
  viridis::scale_color_viridis(discrete = TRUE, option = "rocket") +
  theme(legend.position = "none")

(months_plot+years_plot)/days_plot + plot_annotation(title = "Factors in median ride duration",
                                                     subtitle = "1% of all rides with total duration < 4 hours",
                                                     caption = "Data from NYC Citi Bike system")
```

![](p8105_hw3_jt3466_files/figure-gfm/time%20vs%20median%20ride-1.png)<!-- -->

``` r
# citi_df |> 
#   group_by(weekdays, month, year) |> 
#   summarize(median_duration = median(duration)) |> 
#   mutate(
#     month = as.character(month),
#     year = as.character(year)
#   ) |> 
#   pivot_longer(
#     cols = c(weekdays, month, year),
#     values_to = "time"
#   ) |> 
#   ggplot(aes(x = time, y = median_duration)) +
#   geom_point()
```

- July has a longer median ride duration than January, which makes
  sense, given the summer weather in July is likely more conducive to
  biking than January.
- Interestingly, it seems median ride duration was longer in 2020.
  However, this has a slightly wider interquartile range compared to
  2024.
- The weekdays have a relatively similar median, with a slightly higher
  median duration on Thursdays. Comparatively, Saturday and Sunday have
  higher median durations and wider interquartile ranges, which makes
  sense given people have more time to ride bikes on the weekends.

### Impact of month, membership, and bike type on ride duration in 2024

First, to get data on the factors involved in 2024 ride duration, we
need to `filter` data to include only observations in 2024. Then, we can
create separate graphs for `month` and ride duration, `membership` and
ride duration, and `bike type` and ride duration. Violin plots are used
for all 3 to depict the distribution of ride duration. The median is
depicted as a black dot on the violin plot. Additional data manipulation
is done for the `membership` and `bike type` plots to `mutate` their
values to be capitalized and without underscores so they look better on
the axis labels. The violin plots are grouped together side by side
using the `patchwork` package and likewise has a title over the figure.

``` r
month_ride_2024 <- citi_df |> 
  filter(year == "2024") |> 
  ggplot(aes(x = month, y = duration, fill = month)) + 
  geom_violin() + 
  viridis::scale_fill_viridis(alpha = 0.7, discrete = TRUE, option = "rocket") +
  stat_summary(fun = "median") +
  labs(
    y = "",
    x = "Month"
  ) + 
  theme(legend.position = "none")

membership_ride_2024 <- citi_df |> 
  filter(year == "2024") |> 
  mutate(
    member_casual = case_match(
      member_casual,
      "member" ~ "Member",
      "casual" ~ "Casual",
      .default = member_casual
    )
  ) |> 
  ggplot(aes(x = member_casual, y = duration, fill = member_casual)) + 
  geom_violin() + 
  viridis::scale_fill_viridis(alpha = 0.7, discrete = TRUE, option = "viridis") +
  stat_summary(fun = "median") +
  labs(
    y = "",
    x = "Membership status"
  ) + 
  theme(legend.position = "none")

bike_type_ride_2024 <- citi_df |> 
  filter(year == "2024") |> 
  mutate(
    rideable_type = case_match(
      rideable_type,
      "classic_bike" ~ "Classic bike",
      "electric_bike" ~ "Electric bike",
      .default = rideable_type
    )
  ) |>  
  ggplot(aes(x = rideable_type, y = duration, fill = rideable_type)) + 
  geom_violin() + 
  viridis::scale_fill_viridis(alpha = 0.7, discrete = TRUE, option = "plasma") +
  stat_summary(fun = "median") +
  labs(
    y = "",
    x = "Bike type"
  ) + 
  theme(legend.position = "none")

(month_ride_2024 + membership_ride_2024 + bike_type_ride_2024) + plot_annotation(title = "Factors in 2024 ride duration",
                                                                                 subtitle = "1% of all rides with total duration < 4 hours",
                                                                                 caption = "Data from NYC Citi Bike system")
```

    ## Warning: Removed 2 rows containing missing values or values outside the scale range
    ## (`geom_segment()`).
    ## Removed 2 rows containing missing values or values outside the scale range
    ## (`geom_segment()`).
    ## Removed 2 rows containing missing values or values outside the scale range
    ## (`geom_segment()`).

![](p8105_hw3_jt3466_files/figure-gfm/2024%20ride%20duration%20factors-1.png)<!-- -->

- Between January and July, the median ride duration is slightly higher
  in July. There are a lot more rides in low duration below 12.5 mins
  among January rides, where there are more rides in July that are 25
  mins and up. There is a higher maximum observation in the July rides
  as well.
- There are a lot more members having shorter rides below 12.5 mins
  while casual riders are having longer duration rides. The median ride
  duration between the two are close, but slightly higher in casual
  rides. The maximum ride duration for casual rides is also higher than
  the maximum ride duration for member rides.
- Intriguingly, there are no appreciable differences between the
  distribution of ride duration between classic bikes and electric
  bikes. The medians are comparable and the observations cluster around
  the similar points. There is a slightly higher maximum among electric
  bikes, but that is about the only distinguishing point.
